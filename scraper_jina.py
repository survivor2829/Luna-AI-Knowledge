#!/usr/bin/env python3
"""
ä½¿ç”¨ Jina Reader API å’Œ DeepSeek çš„æ™ºèƒ½çˆ¬è™«
- Jina Reader: è‡ªåŠ¨æå–å¹²å‡€çš„å†…å®¹ï¼ˆå…è´¹ï¼Œæ— éœ€APIå¯†é’¥ï¼‰
- DeepSeek: æ™ºèƒ½å¤„ç†ï¼ˆæ¸…æ´—ã€ç¿»è¯‘ã€æ‘˜è¦ã€æ¦‚å¿µæå–ï¼‰
"""

import re
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, Tuple
import config
from translator_deepseek import DeepSeekTranslator


class JinaReaderScraper:
    """åŸºäºJina Readerçš„æ™ºèƒ½çˆ¬è™«"""

    def __init__(self):
        self.jina_api_base = "https://r.jina.ai"
        self.translator = DeepSeekTranslator()
        self.output_dir = Path.home() / 'Downloads' / 'Luna-AI-Knowledge'
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def fetch_clean_content(self, url: str) -> Tuple[str, str]:
        """
        ä½¿ç”¨ Jina Reader API è·å–å¹²å‡€çš„ Markdown å†…å®¹
        è¿”å›: (å†…å®¹, æ ‡é¢˜)
        """
        print(f"\n{'='*70}")
        print(f"è·å–å†…å®¹: {url}")
        print(f"{'='*70}")

        # æ„å»º Jina Reader URL
        jina_url = f"{self.jina_api_base}/{url}"

        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_attempts = 3
        for attempt in range(1, max_attempts + 1):
            try:
                print(f"  é€šè¿‡ Jina Reader è·å–å†…å®¹ (å°è¯• {attempt}/{max_attempts})...")

                # ä½¿ç”¨ curl é¿å… Python SSL é—®é¢˜
                # -L: è·Ÿéšé‡å®šå‘, -s: é™é»˜æ¨¡å¼, --max-time: è¶…æ—¶, --retry: é‡è¯•æ¬¡æ•°
                result = subprocess.run(
                    ['curl', '-L', '-s', '--max-time', '30', '--retry', '3', '--retry-delay', '2', jina_url],
                    capture_output=True,
                    text=True,
                    timeout=120
                )

                # curl é”™è¯¯ä»£ç : 35 = SSLè¿æ¥é”™è¯¯, å¯ä»¥é‡è¯•
                if result.returncode == 35 and attempt < max_attempts:
                    print(f"  âš ï¸  SSLè¿æ¥å¤±è´¥ (é”™è¯¯ç  35)ï¼Œ{2}ç§’åé‡è¯•...")
                    import time
                    time.sleep(2)
                    continue

                if result.returncode != 0:
                    error_msg = result.stderr if result.stderr else f"curl error code {result.returncode}"
                    raise Exception(f"curl failed: {error_msg}")

                content = result.stdout

                if not content or len(content) < 100:
                    if attempt < max_attempts:
                        print(f"  âš ï¸  å†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œ2ç§’åé‡è¯•...")
                        import time
                        time.sleep(2)
                        continue
                    raise Exception("å†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­")

                # æå–æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ª # æ ‡é¢˜æˆ– "Title:" è¡Œï¼‰
                title_match = re.search(r'^Title:\s*(.+)$', content, re.MULTILINE)
                if not title_match:
                    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)

                title = title_match.group(1) if title_match else self._extract_title_from_url(url)

                print(f"  âœ“ è·å–æˆåŠŸ")
                print(f"  æ ‡é¢˜: {title}")
                print(f"  å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")

                return content, title

            except subprocess.TimeoutExpired:
                if attempt < max_attempts:
                    print(f"  âš ï¸  è¯·æ±‚è¶…æ—¶ï¼Œ2ç§’åé‡è¯•...")
                    import time
                    time.sleep(2)
                    continue
                print(f"  âœ— è¯·æ±‚è¶…æ—¶")
                raise

            except Exception as e:
                if attempt < max_attempts:
                    print(f"  âš ï¸  é”™è¯¯: {e}ï¼Œ2ç§’åé‡è¯•...")
                    import time
                    time.sleep(2)
                    continue
                print(f"  âœ— è·å–å¤±è´¥: {e}")
                raise

    def _extract_title_from_url(self, url: str) -> str:
        """ä»URLä¸­æå–æ ‡é¢˜"""
        # è·å–URLè·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†
        path = url.rstrip('/').split('/')[-1]
        # è½¬æ¢ä¸ºæ ‡é¢˜æ ¼å¼
        title = path.replace('-', ' ').replace('_', ' ').title()
        return title

    def process_with_deepseek(self, content: str, title: str, source_url: str) -> Tuple[str, Dict]:
        """
        ä½¿ç”¨ DeepSeek è¿›è¡Œæ™ºèƒ½å¤„ç†
        è¿”å›: (å¤„ç†åçš„å†…å®¹, å…ƒæ•°æ®)
        """
        print("\nå¤„ç†å†…å®¹...")

        # ä½¿ç”¨ DeepSeek è¿›è¡Œç»¼åˆå¤„ç†
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£å¤„ç†åŠ©æ‰‹ã€‚è¯·å¯¹ç”¨æˆ·æä¾›çš„æŠ€æœ¯æ–‡æ¡£è¿›è¡Œä»¥ä¸‹å¤„ç†ï¼š

1. **å†…å®¹æ¸…æ´—**ï¼šç§»é™¤æ— å…³å†…å®¹ï¼Œä¿ç•™æ ¸å¿ƒæŠ€æœ¯å†…å®¹
2. **ä¸­æ–‡ç¿»è¯‘**ï¼šå°†è‹±æ–‡å†…å®¹ç¿»è¯‘æˆæµç•…ã€ä¸“ä¸šçš„ä¸­æ–‡
3. **ä¿æŒæ ¼å¼**ï¼šä¸¥æ ¼ä¿æŒæ‰€æœ‰ Markdown æ ¼å¼ã€ä»£ç å—ã€é“¾æ¥
4. **æœ¯è¯­å¤„ç†**ï¼šä¿ç•™ APIã€SDKã€LLM ç­‰ä¸“ä¸šæœ¯è¯­çš„è‹±æ–‡

åªè¾“å‡ºå¤„ç†åçš„ä¸­æ–‡å†…å®¹ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–è¯´æ˜ã€‚"""

        try:
            # 1. ç¿»è¯‘ä¸»è¦å†…å®¹ï¼ˆå¤„ç†å¤§æ–‡ä»¶ï¼‰
            print("  1/4 ç¿»è¯‘å†…å®¹...")
            if len(content) > 10000:
                print(f"     å†…å®¹è¾ƒé•¿ ({len(content)} å­—ç¬¦)ï¼Œåˆ†å—å¤„ç†...")
                translated_content = self._translate_large_content(system_prompt, content)
            else:
                translated_content = self._call_deepseek(system_prompt, content, timeout=120)

            # 2. ç”Ÿæˆæ‘˜è¦
            print("  2/4 ç”Ÿæˆæ‘˜è¦...")
            summary = self.translator.generate_summary(translated_content)

            # 3. æå–å…³é”®æ¦‚å¿µï¼ˆå¸¦è§£é‡Šï¼‰
            print("  3/4 æå–å…³é”®æ¦‚å¿µ...")
            key_concepts = self._extract_concepts_with_explanation(translated_content)

            # 4. ç”Ÿæˆé€‚åˆäººç¾¤
            print("  4/4 ç”Ÿæˆé€‚åˆäººç¾¤...")
            target_audience = self.translator.generate_target_audience(translated_content)

            metadata = {
                'title': title,
                'source_url': source_url,
                'scraped_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'summary': summary,
                'key_concepts': key_concepts,
                'target_audience': target_audience
            }

            return translated_content, metadata

        except Exception as e:
            print(f"  âœ— å¤„ç†å¤±è´¥: {e}")
            raise

    def _translate_large_content(self, system_prompt: str, content: str) -> str:
        """åˆ†å—ç¿»è¯‘å¤§æ–‡ä»¶"""
        import time

        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        translated_parts = []
        current_chunk = []
        current_size = 0
        chunk_limit = 8000  # æ¯å—æœ€å¤š8000å­—ç¬¦

        total_chunks = len(paragraphs)
        processed_paras = 0

        for para in paragraphs:
            para_size = len(para)

            if current_size + para_size > chunk_limit and current_chunk:
                # ç¿»è¯‘å½“å‰å—
                chunk_content = '\n\n'.join(current_chunk)
                print(f"     å¤„ç†è¿›åº¦: {processed_paras}/{total_chunks} æ®µè½...")

                translated = self._call_deepseek(
                    system_prompt,
                    chunk_content,
                    timeout=120
                )
                translated_parts.append(translated)

                # é‡ç½®
                current_chunk = [para]
                current_size = para_size
                processed_paras += len(current_chunk)

                time.sleep(1)  # é¿å…APIé™æµ
            else:
                current_chunk.append(para)
                current_size += para_size

        # ç¿»è¯‘æœ€åä¸€å—
        if current_chunk:
            chunk_content = '\n\n'.join(current_chunk)
            print(f"     å¤„ç†è¿›åº¦: {total_chunks}/{total_chunks} æ®µè½...")
            translated = self._call_deepseek(
                system_prompt,
                chunk_content,
                timeout=120
            )
            translated_parts.append(translated)

        return '\n\n'.join(translated_parts)

    def _call_deepseek(self, system_prompt: str, user_content: str, max_tokens: int = 8000, timeout: int = 60) -> str:
        """è°ƒç”¨ DeepSeek API"""
        # ä¸´æ—¶åˆ›å»ºä¸€ä¸ªæ–°clientå®ä¾‹ä»¥ä½¿ç”¨è‡ªå®šä¹‰timeout
        from openai import OpenAI
        client = OpenAI(
            api_key=self.translator.api_key,
            base_url=self.translator.api_url,
            timeout=timeout
        )

        response = client.chat.completions.create(
            model=self.translator.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            max_tokens=max_tokens,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()

    def _extract_concepts_with_explanation(self, content: str) -> list:
        """æå–å…³é”®æ¦‚å¿µå¹¶ç”Ÿæˆè§£é‡Š"""
        sample = content[:5000]

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ¦‚å¿µæå–ä¸“å®¶ã€‚è¯·ä»æ–‡ç« ä¸­æå– {config.KEY_CONCEPTS_COUNT} ä¸ªæœ€é‡è¦çš„å…³é”®æ¦‚å¿µã€‚

å¯¹æ¯ä¸ªæ¦‚å¿µï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ¦‚å¿µåç§° | ç®€çŸ­è§£é‡Šï¼ˆä¸è¶…è¿‡20å­—ï¼‰

ç¤ºä¾‹ï¼š
AI Agent | ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå†³ç­–å’Œè¡ŒåŠ¨çš„æ™ºèƒ½ç³»ç»Ÿ
Prompt Engineering | ä¼˜åŒ–æç¤ºè¯ä»¥æé«˜AIè¾“å‡ºè´¨é‡çš„æŠ€æœ¯

åªè¾“å‡ºæ¦‚å¿µåˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""

        try:
            response = self._call_deepseek(system_prompt, f"è¯·ä»ä»¥ä¸‹æ–‡ç« ä¸­æå–å…³é”®æ¦‚å¿µï¼š\n\n{sample}", max_tokens=500)

            # è§£ææ¦‚å¿µåˆ—è¡¨
            concepts = []
            for line in response.split('\n'):
                line = line.strip()
                if '|' in line and line:
                    concepts.append(line)

            return concepts[:config.KEY_CONCEPTS_COUNT]

        except Exception as e:
            print(f"  âœ— æå–æ¦‚å¿µå¤±è´¥: {e}")
            return ["æ¦‚å¿µæå–å¤±è´¥"]

    def format_output(self, content: str, metadata: Dict) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡º"""

        # æ ¼å¼åŒ–å…³é”®æ¦‚å¿µ
        concepts_formatted = []
        for concept in metadata['key_concepts']:
            if '|' in concept:
                name, explanation = concept.split('|', 1)
                concepts_formatted.append(f"- **{name.strip()}**: {explanation.strip()}")
            else:
                concepts_formatted.append(f"- {concept}")

        output = f"""# {metadata['title']}

> **åŸæ–‡é“¾æ¥ï¼š** {metadata['source_url']}
> **å¤„ç†æ—¶é—´ï¼š** {metadata['scraped_date']}
> **å¤„ç†æ–¹å¼ï¼š** Jina Reader + DeepSeek AI

## ğŸ“ å†…å®¹æ‘˜è¦

{metadata['summary']}

## ğŸ”‘ å…³é”®æ¦‚å¿µ

{chr(10).join(concepts_formatted)}

## ğŸ‘¥ é€‚åˆäººç¾¤

{metadata['target_audience']}

---

## ğŸ“„ æ­£æ–‡å†…å®¹

{content}
"""
        return output

    def save_document(self, content: str, title: str) -> Path:
        """ä¿å­˜æ–‡æ¡£"""
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        safe_filename = re.sub(r'[<>:"/\\|?*]', '', title)
        safe_filename = safe_filename.replace(' ', '_')[:100]  # é™åˆ¶é•¿åº¦
        filename = f"{safe_filename}.md"

        output_path = self.output_dir / filename

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        return output_path

    def scrape_and_process(self, url: str) -> Path:
        """
        å®Œæ•´æµç¨‹ï¼šæŠ“å– -> å¤„ç† -> ä¿å­˜
        """
        print(f"\n{'='*70}")
        print(f"å¼€å§‹å¤„ç†URL: {url}")
        print(f"{'='*70}")

        try:
            # 1. ä½¿ç”¨ Jina Reader è·å–å¹²å‡€å†…å®¹
            raw_content, title = self.fetch_clean_content(url)

            # 2. ä½¿ç”¨ DeepSeek æ™ºèƒ½å¤„ç†
            processed_content, metadata = self.process_with_deepseek(raw_content, title, url)

            # 3. æ ¼å¼åŒ–è¾“å‡º
            final_content = self.format_output(processed_content, metadata)

            # 4. ä¿å­˜æ–‡æ¡£
            output_path = self.save_document(final_content, metadata['title'])

            print(f"\nâœ… å¤„ç†å®Œæˆï¼")
            print(f"ä¿å­˜ä½ç½®: {output_path}")

            return output_path

        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise


def test_scraper():
    """æµ‹è¯•çˆ¬è™«"""
    # éªŒè¯é…ç½®
    issues = config.validate_config()
    if issues:
        print("\né…ç½®é—®é¢˜:")
        for issue in issues:
            print(issue)
        print("\nè¯·å…ˆé…ç½® DeepSeek API å¯†é’¥")
        return

    print(f"\n{'='*70}")
    print("Jina Reader + DeepSeek æ™ºèƒ½çˆ¬è™«æµ‹è¯•")
    print(f"{'='*70}")
    print(f"APIæä¾›å•†: {config.API_PROVIDER}")
    print(f"æ¨¡å‹: {config.DEEPSEEK_MODEL}")
    print(f"{'='*70}")

    # æµ‹è¯•URL
    test_url = "https://www.anthropic.com/research/building-effective-agents"

    # åˆ›å»ºçˆ¬è™«å¹¶å¤„ç†
    scraper = JinaReaderScraper()
    scraper.scrape_and_process(test_url)


if __name__ == '__main__':
    test_scraper()
