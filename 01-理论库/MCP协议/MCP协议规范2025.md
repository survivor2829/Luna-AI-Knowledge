# Model Context Protocol (MCP)

## 本质
一个开放协议，用于标准化大语言模型（LLM）应用与外部数据源及工具之间的连接，解决AI应用获取上下文和执行操作的碎片化问题。

## 原理
**推断原理**：基于**模块化设计**和**标准化接口**原理。它借鉴了软件工程中“协议驱动集成”的思想（如语言服务器协议LSP），通过定义一套通用的JSON-RPC消息格式和交互模式，将复杂的AI能力集成抽象为“服务器”（提供资源、提示词、工具）与“客户端”（AI应用）之间的标准化对话。这降低了系统耦合度，使AI应用能像插件一样动态接入各种能力，符合**接口隔离原则**和**关注点分离**的设计模式。

## 案例
**参考案例**：
*   **背景**：一个开发团队希望在其AI编程助手（如Cursor）中集成公司内部的Jira任务数据和GitLab代码库信息。
*   **做法**：团队为Jira和GitLab分别开发了MCP服务器。这些服务器通过MCP协议向AI编程助手客户端暴露“资源”（如`jira://issue/PROJ-123`）和“工具”（如“创建GitLab合并请求”）。助手在用户询问“帮我看看PROJ-123这个任务相关的代码改动”时，通过MCP协议自动获取Jira任务详情并查询关联的GitLab提交记录。
*   **结果**：开发者在IDE内即可通过自然语言完成跨系统信息查询与操作，无需切换多个工具界面，预计上下文切换时间减少70%，复杂工作流构建速度提升数倍。

## 行动
1.  **第一步（今天就能做）**：访问[MCP官方网站](https://modelcontextprotocol.io/)和[GitHub仓库](https://github.com/modelcontextprotocol)，阅读入门文档，了解核心概念（Host, Client, Server）和协议架构。
2.  **第二步**：根据你的技术栈，选择一个MCP SDK（如TypeScript/Python）开始实践。尝试运行一个现有的示例服务器（如文件系统浏览器），并将其连接到支持MCP的客户端（如Claude Desktop）进行测试。
3.  **第三步**：规划并实现一个简单的自定义MCP服务器，暴露你业务中的一个核心数据源（如数据库表、API接口）作为“资源”或一个简单操作作为“工具”，完成从开发、测试到集成的完整流程。

## 边界
*   ✅ **适用场景**：构建需要动态接入多种数据源和工具的AI应用（如智能IDE、聊天助手、自动化工作流）；希望将内部能力以标准化方式开放给AI生态；需要解耦AI应用与后端服务。
*   ❌ **不适用场景**：对延迟要求极高的实时控制系统；无需外部上下文或工具的简单聊天场景；封闭、单一的数据管道集成。
*   ⚠️ **注意事项**：协议本身不强制执行安全策略，**安全与隐私控制（如用户同意、数据访问授权）必须由实现者（Host）在应用层严格实现**。工具调用等同于代码执行，需谨慎对待其描述和权限。

---
> 来源：https://modelcontextprotocol.io/specification/2025-11-25
> 整理：Mr.Chen
> 日期：2024-05-17