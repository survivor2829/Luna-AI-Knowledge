# 提示工程终极指南

## 本质
提示工程是通过精心设计输入（提示词），以从大语言模型获得最佳、最可靠、最安全输出的实践技能。

## 原理
**推断原理**：提示工程的有效性基于大语言模型的“上下文学习”能力。模型并非执行代码指令，而是根据输入文本的上下文模式来预测和生成最可能的后续文本序列。清晰的提示通过提供明确的模式、结构、角色和示例，减少了模型推理的歧义性，从而将其庞大的知识库和生成能力引导至特定的、符合人类意图的轨道上。其底层结合了**心理学中的框架效应**（问题表述方式影响判断）和**行为经济学中的默认选项设计**（通过预设结构引导选择），本质上是与一个基于统计模式匹配的智能体进行高效、对齐的沟通。

## 案例
**参考案例**：
*   **背景**：某电商公司的客服团队，每天需处理大量用户咨询聊天记录，并生成摘要报告。
*   **做法**：将原本模糊的提示“总结一下聊天内容”优化为结构化提示：“你是一位专业的客服总结助手。请将以下聊天记录总结为三个部分：1. 客户核心问题（用一句话概括）；2. 客户情绪（积极/中性/消极）；3. 解决方案或当前状态。请使用项目符号列表，语言简洁。”
*   **结果**：摘要的准确性和一致性大幅提升，人工复核时间减少约60%，跨团队成员生成的报告格式实现统一。

## 行动
1.  **第一步（今天就能做）**：**明确指令**。在下一次向AI提问时，避免使用“写个总结”这类模糊指令。尝试在任务前加上“角色”和“格式”，例如：“假设你是一位经验丰富的项目经理，请将以下会议纪要的待办事项整理成一个表格，包含‘负责人’、‘任务’和‘截止日期’三列。”
2.  **第二步**：**引入示例（Few-shot）**。对于需要特定格式或风格的任务，在提示中提供1-3个清晰的输入-输出示例。用“###示例###”等分隔符将示例与真实任务分开，明确告诉模型“请按照以上示例的格式处理以下内容”。
3.  **第三步**：**要求分步思考（Chain-of-Thought）**。当面临逻辑推理、数学计算或复杂决策任务时，在提示中明确要求模型“让我们一步步思考”或“请先列出你的推理步骤，再给出最终答案”。这能显著提高复杂任务的准确性。

## 边界
*   ✅ **适用场景**：快速优化现有模型输出、控制生成内容的格式与风格、在不修改模型的情况下探索新功能、进行初步的安全性和对抗性测试。
*   ❌ **不适用场景**：需要模型掌握其训练数据中不存在的新知识或专业技能；需要极端稳定、不可被提示词绕过的行为约束（需依赖模型微调或外部防护）；处理极其复杂、提示词难以描述的长期多轮任务。
*   ⚠️ **注意事项**：提示工程效果因模型而异，需针对不同模型调整策略；过度复杂的提示可能降低可靠性；提示本身可能成为安全漏洞（如提示注入攻击），需在关键应用中结合专业安全防护方案。

---
> 来源：https://www.lakera.ai/blog/prompt-engineering-guide
> 整理：Mr.Chen
> 日期：2024-05-23