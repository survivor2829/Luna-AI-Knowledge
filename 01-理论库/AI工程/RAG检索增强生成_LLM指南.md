# 检索增强生成 (RAG)

## 本质
一种通过为大型语言模型（LLM）引入外部知识库来增强其回答准确性、减少幻觉的技术，核心是“检索-增强-生成”三步流程。

## 原理
**推断原理**：RAG 结合了信息检索系统和生成式模型的优势，其有效性基于以下原理：
1.  **知识解耦**：将模型固有的、静态的“参数化知识”与动态的、可更新的“非参数化知识”（外部数据库）分离，解决了LLM知识更新滞后和领域知识不足的问题。
2.  **证据增强**：通过检索到的相关文档作为生成答案的上下文依据，为LLM的推理过程提供了可追溯的“证据链”，这符合人类的认知习惯（先查证，再回答），从而提高了回答的可信度和可控性。
3.  **注意力引导**：在生成阶段，模型会将注意力更多地集中在提供的检索上下文上，这减少了模型依赖其内部可能不准确或过时参数化知识的倾向，有效抑制了“幻觉”。
4.  **行为经济学中的“可得性启发法”**：模型更容易使用眼前（检索到）的、具体的信息进行回答，而非从海量记忆（参数）中提取，这提升了回答的针对性和相关性。

## 案例
**参考案例**：
*   **背景**：一家跨国金融科技公司，其客服聊天机器人需要回答关于最新产品费率、条款和政策的问题。
*   **做法**：公司构建了一个RAG系统。将最新的产品手册、费率表、监管文件等知识库文档进行分块、向量化并存入向量数据库。当用户提问时，系统首先从向量库中检索最相关的文档片段，然后将这些片段与用户问题一起组合成提示词，发送给GPT-4模型生成最终回答。
*   **结果**：相比直接使用GPT-4，采用RAG后，客服机器人回答的准确率（基于内部知识库验证）从65%提升至92%；关于最新政策变化的提问，幻觉率下降了85%；同时，由于无需为每次知识更新重新训练大模型，维护成本降低了70%。

## 行动
1.  **第一步（今天就能做）**：**明确需求与知识源**。确定你的LLM应用在哪个具体场景下存在知识短板或幻觉问题（例如，回答公司内部制度、最新行业动态）。同时，开始收集和整理相关的、结构化的知识文档（如PDF、Word、网页内容）。
2.  **第二步**：**搭建最小可行RAG原型**。使用如LangChain或LlamaIndex等框架，结合一个开源的嵌入模型（如BGE）和一个轻量级向量数据库（如Chroma或FAISS）。将你整理的知识文档进行文本分块、向量化并存入数据库，然后编写一个简单的检索与提示组合脚本，调用一个API大模型（如GPT-3.5）进行测试。
3.  **第三步**：**评估与迭代优化**。设计测试集，对比使用RAG前后模型回答的准确性。根据结果，优化分块策略（如调整块大小、重叠度）、尝试不同的检索器（如结合关键词与语义的混合搜索）、或优化提示词模板，以提升最终答案的质量。

## 边界
*   ✅ **适用场景**
    *   需要访问特定、最新或私有领域知识的问答系统。
    *   要求回答高度准确、可追溯、减少幻觉的应用（如法律、医疗、金融咨询）。
    *   知识库频繁更新，无法承受频繁重训练大模型成本的场景。
*   ❌ **不适用场景**
    *   任务完全依赖模型的通用推理和创造能力，无需外部事实依据（如写诗、生成创意故事）。
    *   对响应延迟要求极端苛刻（纳秒级），因为检索步骤会增加额外开销。
    *   完全没有可用或可靠外部知识源的场景。
*   ⚠️ **注意事项**
    *   **检索质量是关键**：如果检索不到或检索错误的相关文档，Garbage In, Garbage Out，生成的结果可能更差。
    *   **上下文长度限制**：检索到的文档总量可能超过LLM的上下文窗口，需要压缩或摘要策略。
    *   **知识覆盖度**：RAG的效果受限于外部知识库的完整性和质量，无法回答知识库之外的问题。

---
> 来源：https://www.promptingguide.ai/research/rag
> 整理：Mr.Chen
> 日期：2024-05-25