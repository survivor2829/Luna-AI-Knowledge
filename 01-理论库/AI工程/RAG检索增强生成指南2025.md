# 检索增强生成 (RAG) 2025指南

## 本质
一种将外部知识检索与大语言模型生成能力相结合的AI框架，旨在提升生成内容的准确性和事实依据，解决大模型知识过时、胡编乱造和上下文有限的问题。

## 原理
RAG的核心原理是**将信息检索与文本生成解耦**，通过“检索-增强-生成”的管道化流程，将动态、可更新的外部知识库作为生成模型的“工作记忆”。其有效性基于：
1.  **模块化设计**：将知识存储（检索器）与知识运用（生成器）分离，允许各自独立优化和更新。
2.  **向量语义检索**：利用嵌入模型将文本转化为高维向量，通过计算向量相似度（如余弦相似度）实现基于语义而非关键词的精准检索。
3.  **上下文注入**：将检索到的相关文档作为额外上下文提示（Prompt）输入给生成模型，引导模型基于给定事实进行生成，减少幻觉。
4.  **行为经济学原理 - 禀赋效应**：模型在生成时，会倾向于使用和依赖已经“拥有”（即被检索到并呈现）的上下文信息，从而更忠实于事实。

## 案例
**背景**：一家大型金融机构的智能客服系统，需要回答关于不断更新的金融产品条款和法规的客户咨询。
**做法**：
1.  将最新的产品手册、法规文档和内部知识库进行分块并向量化，存入向量数据库。
2.  当客户提问“XX理财产品的提前赎回费率是多少？”时，系统首先将问题编码为向量。
3.  从向量数据库中检索与问题最相关的3-5个文档片段（如产品说明书的具体章节）。
4.  将问题和这些检索到的片段一起输入给大语言模型（如GPT-4），生成最终回答。
**结果**：相比直接使用大语言模型，RAG系统将回答的准确率从约70%提升至95%以上，并显著减少了因知识过时导致的错误。客服工单处理效率提升30%。

## 行动
1.  **第一步（今天就能做）**：**明确需求与知识源**。确定你的应用场景（如客服、文档问答）需要哪些外部知识（公司文档、产品手册、网页等），并开始收集和整理这些非结构化文档。
2.  **第二步**：**搭建基础RAG管道原型**。使用开源工具（如LangChain、LlamaIndex），选择一个嵌入模型（如`text-embedding-ada-002`）和一个向量数据库（如Chroma、FAISS），将你的文档进行分块、向量化并存储。然后连接一个开源或API大模型（如GPT、Claude），测试简单的问答流程。
3.  **第三步**：**评估与优化**。用一批真实问题测试你的RAG原型，评估回答质量。根据问题（如检索不相关、生成不准确）尝试进阶技术：若文档长且复杂，考虑**Long RAG**优化分块策略；若需更高准确性，研究引入**Self-RAG**的自反思机制或**Corrective RAG**的错误纠正机制。

## 边界
-   ✅ **适用场景**：知识密集型问答、基于文档的聊天机器人、需要引用来源的内容生成、企业知识库查询、法律/医疗等专业领域咨询。
-   ❌ **不适用场景**：开放式的创意写作（如写诗、编故事）、纯逻辑推理或数学计算、实时性要求极高的简单对话（因检索增加延迟）。
-   ⚠️ **注意事项**：
    -   **检索质量是关键**：垃圾进，垃圾出。知识库的质量、文档分块的粒度、检索算法的精度直接决定最终效果。
    -   **无法解决所有幻觉**：即使提供了正确文档，生成模型仍可能误解或忽略部分内容。
    -   **存在延迟**：检索步骤会增加系统响应时间，需在准确性和速度间权衡。
    -   **知识更新有成本**：外部知识库更新后，需要重新进行向量化嵌入，涉及计算和存储成本。

---
> 来源：https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag
> 整理：Mr.Chen
> 日期：2024-05-19